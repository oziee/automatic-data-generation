{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib qt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import torchtext\n",
    "import torch.nn as nn\n",
    "cmap = plt.get_cmap('viridis')\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = '/Users/stephane/Dropbox/Work/Codes/data/'\n",
    "datadir = '/Users/stephane/Dropbox/Work/Codes/data/2017-06-custom-intent-engines/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PlayMusic',\n",
       " 'RateBook',\n",
       " 'SearchCreativeWork',\n",
       " 'GetWeather',\n",
       " 'BookRestaurant',\n",
       " 'AddToPlaylist',\n",
       " 'SearchScreeningEvent']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(datadir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from nltk import word_tokenize\n",
    "import spacy\n",
    " \n",
    "tokenizer = 'nltk'\n",
    "\n",
    "if tokenizer == 'spacy':\n",
    "    from spacy.symbols import ORTH\n",
    "    my_tok = spacy.load('en')\n",
    "    my_tok.tokenizer.add_sp\n",
    "    def tokenize(x):\n",
    "        return [tok.text for tok in my_tok.tokenizer(x)]\n",
    "elif tokenizer=='nltk':\n",
    "    tokenize = word_tokenize\n",
    "elif tokenizer=='split':\n",
    "    tokenize = lambda s : s.split(\" \")\n",
    "\n",
    "TEXT   = torchtext.data.Field(lower=True, tokenize=tokenize, sequential=True, batch_first=False)\n",
    "DELEX  = torchtext.data.Field(lower=True, tokenize=tokenize, sequential=True, batch_first=False)\n",
    "INTENT = torchtext.data.Field(sequential=False, batch_first=True)\n",
    "\n",
    "datafields = [(\"utterance\", TEXT), (\"labels\", None), (\"delexicalised\", DELEX), (\"intent\", INTENT)]\n",
    "\n",
    "trn, vld = torchtext.data.TabularDataset.splits(\n",
    "               path='.', # the root directory where the data lies\n",
    "               train='data/train.csv', validation='data/validate.csv',\n",
    "               format='csv',\n",
    "               skip_header=True, # if your csv header has a header, make sure to pass this to ensure it doesn't get proceesed as data!\n",
    "               fields=datafields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Iterator, BucketIterator\n",
    "\n",
    "TEXT.build_vocab(trn, vectors=\"glove.6B.100d\")\n",
    "DELEX.build_vocab(trn, vectors=\"glove.6B.100d\")\n",
    "INTENT.build_vocab(trn)\n",
    "\n",
    "# make iterator for splits\n",
    "bs=64\n",
    "\n",
    "train_iter, val_iter = BucketIterator.splits(\n",
    "    (trn, vld), # we pass in the datasets we want the iterator to draw data from\n",
    "    batch_sizes=(bs, bs),\n",
    "    device='cpu', # if you want to use the GPU, specify the GPU number here\n",
    "    sort_key=lambda x: len(x.utterance), # the BucketIterator needs to be told what function it should use to group the data.\n",
    "    sort_within_batch=False,\n",
    "    repeat=False, # we pass repeat=False because we want to wrap this Iterator layer.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11704 698\n"
     ]
    }
   ],
   "source": [
    "print(len(TEXT.vocab.itos), len(DELEX.vocab.itos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', 'the', 'a', 'in', 'to', 'for', 'of', 'at', 'play']\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', 'the', 'a', 'to', 'for', 'in', '_object_type_', 'at', 'play']\n"
     ]
    }
   ],
   "source": [
    "print(DELEX.vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0382, -0.2449,  0.7281, -0.3996,  0.0832,  0.0440, -0.3914,  0.3344,\n",
       "        -0.5755,  0.0875,  0.2879, -0.0673,  0.3091, -0.2638, -0.1323, -0.2076,\n",
       "         0.3340, -0.3385, -0.3174, -0.4834,  0.1464, -0.3730,  0.3458,  0.0520,\n",
       "         0.4495, -0.4697,  0.0263, -0.5415, -0.1552, -0.1411, -0.0397,  0.2828,\n",
       "         0.1439,  0.2346, -0.3102,  0.0862,  0.2040,  0.5262,  0.1716, -0.0824,\n",
       "        -0.7179, -0.4153,  0.2033, -0.1276,  0.4137,  0.5519,  0.5791, -0.3348,\n",
       "        -0.3656, -0.5486, -0.0629,  0.2658,  0.3020,  0.9977, -0.8048, -3.0243,\n",
       "         0.0125, -0.3694,  2.2167,  0.7220, -0.2498,  0.9214,  0.0345,  0.4674,\n",
       "         1.1079, -0.1936, -0.0746,  0.2335, -0.0521, -0.2204,  0.0572, -0.1581,\n",
       "        -0.3080, -0.4162,  0.3797,  0.1501, -0.5321, -0.2055, -1.2526,  0.0716,\n",
       "         0.7056,  0.4974, -0.4206,  0.2615, -1.5380, -0.3022, -0.0734, -0.2831,\n",
       "         0.3710, -0.2522,  0.0162, -0.0171, -0.3898,  0.8742, -0.7257, -0.5106,\n",
       "        -0.5203, -0.1459,  0.8278,  0.2706])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DELEX.vocab.vectors[DELEX.vocab.stoi['the']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Karpathy CharRNN\n",
    "\n",
    "### Temperature: 0.2\n",
    "\n",
    "I want to book a reservation for a restaurant for a party of a party of 6 points\n",
    "\n",
    "I want to book a reservation for a restaurant for a restaurant for a restaurant in Barken Marcha at a party of 6\n",
    "\n",
    "I need a table for a restaurant for a party of a party of 6 points\n",
    "\n",
    "### Temperature: 0.5\n",
    "I need a table for a reservation for a restaurant in the area that serves find movement in the area at a party of a siming from now\n",
    "\n",
    "I want to half album to Musaf Rock Story Barb playlist.\n",
    "\n",
    "I want to give this current book The Very Satarora for the twenty-textbook.\n",
    "\n",
    "### Temperature: 1.0\n",
    "What will the weather be syar llind in Playlin Man.\n",
    "\n",
    "Tell it i from the Shawnua Tf Hiss Morny Cimes\n",
    "\n",
    "Hadon in a top-fight?\n",
    "\n",
    "play the song from the fifties for ten in Mondital Maker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "run = torch.load('run.pyT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1,3, figsize=(20,6))\n",
    "axarr = axarr.flatten()\n",
    "\n",
    "args = run['args']\n",
    "NLL_hist = run['NLL_hist']\n",
    "KL_hist  = run['KL_hist' ]\n",
    "NMI_hist = run['NMI_hist']\n",
    "t = np.array(range(len(NLL_hist)))\n",
    "\n",
    "from train import kl_anneal_function\n",
    "kl_anneal_function = np.vectorize(kl_anneal_function)\n",
    "KL_weight = kl_anneal_function(args.anneal_function, t, args.k, args.x0)\n",
    "\n",
    "axarr[0].plot(t, NLL_hist)\n",
    "axarr[1].plot(t, KL_hist )\n",
    "ax2 = axarr[1].twinx()\n",
    "ax2.plot(t, KL_weight, color='red')\n",
    "axarr[2].plot(t, NMI_hist)\n",
    "for i in range(3):\n",
    "    axarr[i].set_xlabel('Iterations')\n",
    "axarr[0].set_ylabel('Reconstruction loss')\n",
    "axarr[1].set_ylabel('KL loss')\n",
    "ax2.set_ylabel('KL_weight', color='red')\n",
    "axarr[2].set_ylabel('NMI')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 3)\n",
      "(6000, 3)\n",
      "(5919, 3)\n",
      "(5877, 3)\n",
      "(5868, 3)\n",
      "(5862, 3)\n",
      "(5826, 3)\n"
     ]
    }
   ],
   "source": [
    "n_per_intent = 300\n",
    "\n",
    "latent = run['latent']\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "all_latent = sum([latent_list for latent_list in latent.values()], [])\n",
    "pca.fit(all_latent)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for intent in latent.keys():\n",
    "    points = pca.transform(latent[intent])\n",
    "    #points = np.array(latent[intent])\n",
    "    ax.scatter(points[:n_per_intent,0], points[:n_per_intent,1], points[:n_per_intent,2], c=[cmap(intent/len(latent.keys()))], label='{}'.format(intent))\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
